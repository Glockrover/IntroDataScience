<!DOCTYPE html>
<html>
  <head>
    <title>Introduction to Data Science Programming in Python</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
        color:darkslategrey;
      }
      h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .font40 {
        font-size: 40px;
      }
      .font30 {
        font-size: 30px;
      }
      .font20 {
        font-size: 20px;
      }
      .remark-code, .remark-inline-code {
         font-family: 'Ubuntu Mono';
         font-size: 20px;
         }
            /* Two-column layout */
      .left-column {
        color: #777;
        width: 50%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 50%;
        float: right;
        padding-top: 1em;
      }
      .right-column h2:last-of-type, .right-column h3:last-child {
          color: #000;
        }
      .inverse {
        background: #272822;
        color: #e4e4e1;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2, .inverse h3 {
        color: #f3f3f3;
        line-height: 0.8em;
      }
      .lightfont {color:rgb(129, 126, 126);
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle, font30

# Data Science Programming in Python

J. Hathaway: BYU-I Data Science Program Chair
U. Ugoh: Data Scientist and Developer with DataThink
N. Ugho: Developer with DataThink

---
class: font30

# Disclaimers

I am focusing on modern tools for data science in Python - Polars over Pandas, Plotly over Matplotlib, and Streamlit over Dash, Marimo over Jupyter.  These modern tools reflect the best of

- declarative programming (task focused programming)
- clean grammar (language abstraction that allows intuitive but complex actions)
- industry respect (all four tools are very popular for the quality and have rapid growth)

---
class: font40
# Agenda

Exemplify the data science process - Extract, Transform, Load, Analyze

1. Introduction and Set-up (30 minutes)
2. Polars for data munging (45 minutes)
3. Break (10 minutes)
4. Plotly for data visualization (45 minutes)
5. Streamlit for dashboards (45 minutes)


---
class: font20
# Introduction to Polars and Data Munging (speed)

> Polars is a lightning fast DataFrame library/in-memory query engine. Its embarrassingly parallel execution, cache efficient algorithms and expressive API makes it perfect for efficient data wrangling, data pipelines, snappy APIs and so much more. Polars is about as fast as it gets, see the results in the [H2O.ai benchmark](https://h2oai.github.io/db-benchmark/).
> </br>
> [Polars Website](https://www.pola.rs/)

![:scale 60%](https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg)

---

# Introduction to Polars and Data Munging (declarative API)

Polars functions (Contexts & Expressions) are human readable and they align with standard SQL methods as well as the very popular big data package [PySpark](https://www.databricks.com/glossary/pyspark).

## Contexts

- __Selection:__ `df.select([..])`, `df.with_columns([..])`
- __Filtering:__ `df.filter()`
- __Groupby/Aggregation:__ `df.groupby(..).agg([..])`

## Expressions

```python
new_df = df.select(
  pl.col("names").n_unique().alias("unique"),
  pl.approx_unique("names").alias("unique_approx"),
  (pl.col("nrs").sum() + 5).alias("nrs + 5"),
  pl.col("integers").cast(pl.Float32).alias("integers_as_floats"),
  pl.col("animal").str.n_chars().alias("letter_count")
)
```

---
class: font30
# Polars programming


Now let's practice using Polars with our installation of Python

1. Read data, melt data, and save as `.parquet` (01_read.py)
2. Munge data for visualization (02_munge.py)

![:scale 75%](https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg)

---
class: font20
# Introduction to Parquet files

When users ask for data or when many institutions share data the files are usually some type of text file (`.txt`, `.csv`, `.tsv`) or an Excel file. The most ubiquitous format is `.csv`. However, these formats limit effective data handling.  We want a format that stores small, reads fast, and maintains variable types. The [Apache Arrow project](https://arrow.apache.org/) facilitates the goal with the `.parquet` and `.feather` formats and their respective packages for leveraging those formats.

The following table from the [openbridge blog](https://blog.openbridge.com/how-to-be-a-hero-with-powerful-parquet-google-and-amazon-f2ae0f35ee04) provides a strong example of the benefits of these new formats.

![:scale 95%](https://raw.githubusercontent.com/hathawayj/ghana_datascience/master/img/csv_parquet.png)



## üìö Learning Path

### Overview and Setup (40 minutes)

‚úì Overview of Data Science and Tools
‚úì Install VS Code and UV  
‚úì Clone repository and sync dependencies  
‚úì Launch first notebook

### Phase 1: Learn the Basics (1 hour)

**üìì Notebook 1: Python Basics** (20 min)

- Variables, data types, and operations
- Lists and dictionaries
- Control flow (if/else, loops)
- Functions

**üìì Notebook 2: Data Wrangling** (20 min)

- Loading data (CSV, JSON, Parquet)
- Exploring DataFrames with Polars
- Filtering, selecting, and transforming data
- Joining datasets

**üìì Notebook 3: Plotting** (20 min)

- Line charts and bar charts
- Scatter plots and histograms
- Customizing visualizations
- Subplots

### Phase 2: Practice (1 hour)

**‚úèÔ∏è Exercise 1: Fundamentals** (20 min)

- Practice Python basics
- 8-10 hands-on exercises

**‚úèÔ∏è Exercise 2: Basic Data Wrangling with Polars** (20 min)

- Load and manipulate real datasets
- Answer questions with data

**‚úèÔ∏è Exercise 3: Basic Plotting with Plotly** (20 min)

- Create visualizations from data
- Hands-on exercises

**Total Time**: ~3 hours 


---
class: font40
# Next Steps

1. Program your day (incorporate programming into your daily work)
2. Grow your skills -- [BYU-I DS 250 Course](https://byuistats.github.io/DS250-Course/) and [BYU-I CSE 450 Course](https://byui-cse.github.io/cse450-course/)
3. Challenge others -- [Tidy Tuesday](https://github.com/rfordatascience/tidytuesday)
4. Display your talent -- [Github.com](https://github.com/hathawayj)
5. Offer your services -- Find small projects to do for friends and contacts
6. Apply for jobs -- [LinkedIn](https://www.linkedin.com/jobs/search/?currentJobId=3636093741&geoId=104353902&keywords=data%20science&location=Greater%20Accra%20Region%2C%20Ghana&originalSubdomain=gh&refresh=true)


---



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      remark.macros.upper = function () {
        // `this` is the value in the parenthesis, or undefined if left out
        return this.toUpperCase();
      };

      remark.macros.random = function () {
        // params are passed as function arguments: ["one", "of", "these", "words"]
        var i = Math.floor(Math.random() * arguments.length);
        return arguments[i];
      };

      remark.macros.scale = function (percentage) {
        var url = this;
        return '<img src="' + url + '" style="width: ' + percentage + '" />';
      };

      var slideshow = remark.create({
        ratio: "16:9",
        highlightLanguage: 'javascript',
        highlightStyle: 'monokai'
       });
    </script>
  </body>
</html>
